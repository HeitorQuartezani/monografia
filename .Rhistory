# Define as colunas de Fatores (Parâmetros) e Métricas (Respostas)
fatores_independentes <- c(
"chunking_strategy",
"search_type",
"model",
"top_k",
)
# ==============================================================================
# SCRIPT DE ANÁLISE ESTATÍSTICA (ANOVA) PARA RESULTADOS DE RAG
#
# OBJETIVO:
# 1. Carregar e limpar os dados do experimento.
# 2. Executar um ANOVA N-Way para identificar quais parâmetros (fatores)
#    têm um impacto estatisticamente significativo nas métricas de score.
# 3. Verificar os pressupostos do ANOVA (Normalidade e Homogeneidade).
# 4. Executar um teste Post-Hoc (Tukey) para descobrir *quais* grupos
#    são diferentes (ex: 'hibrida' vs 'vetorial').
# ==============================================================================
# --- 1. Carregar Bibliotecas ---
library(dplyr)    # Para manipulação de dados (ex: mutate, select)
library(broom)    # Para limpar os outputs do modelo (tidy)
library(car)      # Para o Teste de Levene (pressuposto do ANOVA)
library(ggpubr)   # Para visualização (ex: ggqqplot)
# --- 2. Configuração dos Nomes (AJUSTE AQUI) ---
# O nome do seu arquivo CSV final
ARQUIVO_CSV <- "dados.csv"
# O nome do LLM Juiz que você usou no script 'analise_metricas.py'
# (Usado para encontrar as colunas de score)
LLM_JUIZ_SUFFIX <- "_gpt-4o" # Mude se você usou 'gpt-4o-mini' como juiz
# --- 3. Carregar e Limpar os Dados ---
# Garante que o R está lendo o arquivo do diretório correto
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# Carrega os dados
dados <- read.csv(ARQUIVO_CSV)
# Define as colunas de Fatores (Parâmetros) e Métricas (Respostas)
fatores_independentes <- c(
"chunking_strategy",
"search_type",
"model",
"top_k"
)
# Nomes base das métricas que queremos analisar
metricas_dependentes_base <- c(
"faithfulness",
"answer_correctness",
"context_recall",
"context_precision",
"answer_relevancy"
)
# Cria os nomes completos das colunas de score (ex: "faithfulness_gpt-4o")
metricas_dependentes <- paste0(metricas_dependentes_base, LLM_JUIZ_SUFFIX)
# Verifica se as colunas existem
colunas_necessarias <- c(fatores_independentes, metricas_dependentes)
colunas_ausentes <- setdiff(colunas_necessarias, names(dados))
if (length(colunas_ausentes) > 0) {
stop(paste("ERRO: Colunas não encontradas no CSV:", paste(colunas_ausentes, collapse=", ")))
}
# ==============================================================================
# SCRIPT DE ANÁLISE ESTATÍSTICA (ANOVA) PARA RESULTADOS DE RAG
#
# OBJETIVO:
# 1. Carregar e limpar os dados do experimento.
# 2. Executar um ANOVA N-Way para identificar quais parâmetros (fatores)
#    têm um impacto estatisticamente significativo nas métricas de score.
# 3. Verificar os pressupostos do ANOVA (Normalidade e Homogeneidade).
# 4. Executar um teste Post-Hoc (Tukey) para descobrir *quais* grupos
#    são diferentes (ex: 'hibrida' vs 'vetorial').
# ==============================================================================
# --- 1. Carregar Bibliotecas ---
library(dplyr)    # Para manipulação de dados (ex: mutate, select)
library(broom)    # Para limpar os outputs do modelo (tidy)
library(car)      # Para o Teste de Levene (pressuposto do ANOVA)
library(ggpubr)   # Para visualização (ex: ggqqplot)
# --- 2. Configuração dos Nomes (AJUSTE AQUI) ---
# O nome do seu arquivo CSV final
ARQUIVO_CSV <- "dados.csv"
# O nome do LLM Juiz que você usou no script 'analise_metricas.py'
# (Usado para encontrar as colunas de score)
LLM_JUIZ_SUFFIX <- "" # Mude se você usou 'gpt-4o-mini' como juiz
# --- 3. Carregar e Limpar os Dados ---
# Garante que o R está lendo o arquivo do diretório correto
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# Carrega os dados
dados <- read.csv(ARQUIVO_CSV)
# Define as colunas de Fatores (Parâmetros) e Métricas (Respostas)
fatores_independentes <- c(
"chunking_strategy",
"search_type",
"model",
"top_k"
)
# Nomes base das métricas que queremos analisar
metricas_dependentes_base <- c(
"faithfulness",
"answer_correctness",
"context_recall",
"context_precision",
"answer_relevancy"
)
# Cria os nomes completos das colunas de score (ex: "faithfulness_gpt-4o")
metricas_dependentes <- paste0(metricas_dependentes_base, LLM_JUIZ_SUFFIX)
# Verifica se as colunas existem
colunas_necessarias <- c(fatores_independentes, metricas_dependentes)
colunas_ausentes <- setdiff(colunas_necessarias, names(dados))
if (length(colunas_ausentes) > 0) {
stop(paste("ERRO: Colunas não encontradas no CSV:", paste(colunas_ausentes, collapse=", ")))
}
# ==============================================================================
# SCRIPT DE ANÁLISE ESTATÍSTICA (ANOVA) PARA RESULTADOS DE RAG
#
# OBJETIVO:
# 1. Carregar e limpar os dados do experimento.
# 2. Executar um ANOVA N-Way para identificar quais parâmetros (fatores)
#    têm um impacto estatisticamente significativo nas métricas de score.
# 3. Verificar os pressupostos do ANOVA (Normalidade e Homogeneidade).
# 4. Executar um teste Post-Hoc (Tukey) para descobrir *quais* grupos
#    são diferentes (ex: 'hibrida' vs 'vetorial').
# ==============================================================================
# --- 1. Carregar Bibliotecas ---
library(dplyr)    # Para manipulação de dados (ex: mutate, select)
library(broom)    # Para limpar os outputs do modelo (tidy)
library(car)      # Para o Teste de Levene (pressuposto do ANOVA)
library(ggpubr)   # Para visualização (ex: ggqqplot)
# --- 2. Configuração dos Nomes (AJUSTE AQUI) ---
# O nome do seu arquivo CSV final
ARQUIVO_CSV <- "dados.csv"
# O nome do LLM Juiz que você usou no script 'analise_metricas.py'
# (Usado para encontrar as colunas de score)
LLM_JUIZ_SUFFIX <- "_gpt.4o" # Mude se você usou 'gpt-4o-mini' como juiz
# --- 3. Carregar e Limpar os Dados ---
# Garante que o R está lendo o arquivo do diretório correto
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# Carrega os dados
dados <- read.csv(ARQUIVO_CSV)
# Define as colunas de Fatores (Parâmetros) e Métricas (Respostas)
fatores_independentes <- c(
"chunking_strategy",
"search_type",
"model",
"top_k"
)
# Nomes base das métricas que queremos analisar
metricas_dependentes_base <- c(
"faithfulness",
"answer_correctness",
"context_recall",
"context_precision",
"answer_relevancy"
)
# Cria os nomes completos das colunas de score (ex: "faithfulness_gpt-4o")
metricas_dependentes <- paste0(metricas_dependentes_base, LLM_JUIZ_SUFFIX)
# Verifica se as colunas existem
colunas_necessarias <- c(fatores_independentes, metricas_dependentes)
colunas_ausentes <- setdiff(colunas_necessarias, names(dados))
if (length(colunas_ausentes) > 0) {
stop(paste("ERRO: Colunas não encontradas no CSV:", paste(colunas_ausentes, collapse=", ")))
}
# Limpeza e Preparação
dados_limpos <- dados %>%
# Converte todos os fatores independentes para o tipo 'factor' (essencial para ANOVA)
mutate(across(all_of(fatores_independentes), as.factor)) %>%
# Converte o 'top_k' (que é numérico) para fator também, pois é uma categoria
mutate(top_k = as.factor(top_k)) %>%
# Remove quaisquer linhas que tenham NA (Nulo) nas métricas que vamos analisar
# Isso é crucial, pois o ANOVA não roda com valores ausentes.
select(all_of(colunas_necessarias)) %>%
na.omit()
print(paste("Dados carregados e limpos. Total de linhas para análise:", nrow(dados_limpos)))
View(dados_limpos)
View(dados)
# Esta função executa todo o pipeline de análise para uma métrica
executar_analise_anova <- function(dados, metrica_nome) {
print(paste("--- INICIANDO ANÁLISE PARA:", metrica_nome, "---"))
# Cria a fórmula do modelo.
# Vamos analisar os "Efeitos Principais" (o impacto de cada parâmetro isoladamente)
# Esta é a forma mais simples e robusta de começar.
formula_anova <- as.formula(paste(
metrica_nome, "~", paste(fatores_independentes, collapse = " + ")
))
# Modelo alternativo (mais avançado) com interações de 2 vias:
# formula_anova <- as.formula(paste(
#   metrica_nome, "~ (", paste(fatores_independentes, collapse = " + "), ")^2"
# ))
# 4a. Rodar o Modelo ANOVA
modelo <- aov(formula_anova, data = dados)
print("Resultados do ANOVA (Sumário do Modelo):")
print(summary(modelo))
# 4b. Verificar Pressupostos (Importante para o TCC)
# O ANOVA só é 100% válido se os resíduos forem normais e as variâncias homogêneas.
residuos_modelo <- residuals(modelo)
# 1. Teste de Normalidade dos Resíduos (Shapiro-Wilk)
# H0 (Hipótese Nula): Os dados são normalmente distribuídos.
# Se p < 0.05, os dados NÃO são normais.
if (length(residuos_modelo) > 5000) {
print("Muitos resíduos (>5000) para Shapiro-Wilk. Usando uma amostra.")
shapiro_teste <- shapiro.test(sample(residuos_modelo, 5000))
} else {
shapiro_teste <- shapiro.test(residuos_modelo)
}
print("Teste de Normalidade (Shapiro-Wilk):")
print(shapiro_teste)
# 2. Teste de Homogeneidade das Variâncias (Levene)
# H0 (Hipótese Nula): As variâncias entre os grupos são iguais.
# Se p < 0.05, as variâncias NÃO são iguais (heterocedasticidade).
print("Teste de Homogeneidade (Levene):")
print(leveneTest(formula_anova, data = dados))
# Mensagem de Aviso para o TCC
if (shapiro_teste$p.value < 0.05) {
print("AVISO (Normalidade): O p-valor do Shapiro-Wilk é < 0.05. Os resíduos NÃO são normais.")
print("Considere usar um teste não-paramétrico (ex: Kruskal-Wallis) ou um GLM (Modelo Linear Generalizado) para sua análise final.")
}
# 4c. Teste Post-Hoc (Tukey HSD)
# Se o ANOVA mostrou que um fator é significativo (ex: Pr(>F) < 0.05),
# este teste nos diz QUAIS grupos são diferentes entre si.
print("--- Resultados do Teste Post-Hoc (Tukey HSD) ---")
# Vamos fazer como exemplo para os 3 fatores mais importantes de RAG:
print("Comparação para 'search_type':")
print(TukeyHSD(modelo, which = "search_type"))
print("Comparação para 'chunking_strategy':")
print(TukeyHSD(modelo, which = "chunking_strategy"))
print("Comparação para 'system_prompt_override':")
print(TukeyHSD(modelo, which = "system_prompt_override"))
print(paste("--- ANÁLISE PARA:", metrica_nome, "CONCLUÍDA ---"))
}
# Exemplo de análise para 'faithfulness' (Anti-Alucinação)
executar_analise_anova(dados_limpos, paste0("faithfulness", LLM_JUIZ_SUFFIX))
# ==============================================================================
# SCRIPT DE ANÁLISE ESTATÍSTICA (ANOVA) PARA RESULTADOS DE RAG
#
# CORREÇÃO (v1.2):
# - Corrige o erro do 'leveneTest' (Model must be completely crossed).
# - O teste de homogeneidade agora é executado em um loop, individualmente
#   para cada fator, o que é mais robusto.
# ==============================================================================
# --- 1. Carregar Bibliotecas ---
library(dplyr)    # Para manipulação de dados
library(broom)    # Para limpar os resultados do modelo
library(car)      # Para o Teste de Levene
library(ggpubr)   # Para visualização
# --- 2. Configuração dos Nomes (AJUSTE AQUI) ---
ARQUIVO_CSV <- "dados.csv"
# IMPORTANTE: Verifique o nome das colunas de score no seu CSV.
# Elas são 'faithfulness' ou 'faithfulness_gpt-4o'?
# Se não houver sufixo (como no seu CSV), deixe esta variável como "".
LLM_JUIZ_SUFFIX <- "" # No seu CSV, não há sufixo (ex: _gpt-4o)
# --- 3. Carregar e Limpar os Dados ---
# Carrega os dados
# (Assumindo que o R e o CSV estão no mesmo diretório de trabalho)
# Se estiver usando RStudio, você pode definir o diretório com:
# setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
dados <- read.csv(ARQUIVO_CSV)
# Ajustamos os fatores para bater com o seu CSV
fatores_independentes <- c(
"chunking_strategy",
"search_type",
"model",
"top_k",
"temperature"
)
metricas_dependentes_base <- c(
"faithfulness",
"answer_relevancy",
"context_recall",
"context_precision",
"answer_correctness"
)
metricas_dependentes <- paste0(metricas_dependentes_base, LLM_JUIZ_SUFFIX)
# Verifica se as colunas existem
colunas_necessarias <- c(fatores_independentes, metricas_dependentes)
colunas_ausentes <- setdiff(colunas_necessarias, names(dados))
if (length(colunas_ausentes) > 0) {
print(paste("AVISO: As seguintes colunas não foram encontradas:", paste(colunas_ausentes, collapse=", ")))
# Remove da lista as métricas/fatores que não foram encontrados
metricas_dependentes <- setdiff(metricas_dependentes, colunas_ausentes)
fatores_independentes <- setdiff(fatores_independentes, colunas_ausentes)
}
colunas_para_analise <- c(fatores_independentes, metricas_dependentes)
# Limpeza e Preparação
dados_limpos <- dados %>%
mutate(across(all_of(fatores_independentes), as.factor)) %>%
mutate(top_k = as.factor(top_k),
temperature = as.factor(temperature)) %>%
select(all_of(colunas_para_analise)) %>%
na.omit()
print(paste("Dados carregados e limpos. Total de linhas para análise:", nrow(dados_limpos)))
executar_analise_anova <- function(dados, metrica_nome) {
print(paste("--- INICIANDO ANÁLISE PARA:", metrica_nome, "---"))
formula_anova <- as.formula(paste(
metrica_nome, "~", paste(fatores_independentes, collapse = " + ")
))
# 4a. Rodar o Modelo ANOVA
modelo <- aov(formula_anova, data = dados)
print("Resultados do ANOVA (Sumário do Modelo):")
print(summary(modelo))
# 4b. Verificar Pressupostos
residuos_modelo <- residuals(modelo)
# Teste de Normalidade (Shapiro-Wilk)
if (length(residuos_modelo) > 5000) {
print("Muitos resíduos (>5000) para Shapiro-Wilk. Usando uma amostra de 5000.")
shapiro_teste <- shapiro.test(sample(residuos_modelo, 5000))
} else {
shapiro_teste <- shapiro.test(residuos_modelo)
}
print("Teste de Normalidade (Shapiro-Wilk):")
print(shapiro_teste)
if (shapiro_teste$p.value < 0.05) {
print("AVISO (Normalidade): O p-valor do Shapiro-Wilk é < 0.05. Os resíduos NÃO são normais.")
print("Para o TCC, reporte isso e considere usar um teste não-paramétrico (ex: Kruskal-Wallis).")
}
# === CORREÇÃO DO TESTE DE LEVENE ===
print("Teste de Homogeneidade (Levene) - (Testando cada fator individualmente):")
# O Levene Test falha com fórmulas complexas (+).
# Vamos testar a homogeneidade para cada fator principal, um de cada vez.
for (fator in fatores_independentes) {
formula_levene <- as.formula(paste(metrica_nome, "~", fator))
print(paste("--- Resultado do Teste de Levene para o fator:", fator, "---"))
# Roda o teste para o fator atual
teste_levene <- leveneTest(formula_levene, data = dados)
print(teste_levene)
# Extrai o p-valor
levene_p_value <- teste_levene$`Pr(>F)`[1]
# H0 (Hipótese Nula): As variâncias são iguais.
# Se p < 0.05, as variâncias NÃO são iguais (violou o pressuposto).
if (levene_p_value < 0.05) {
print(paste("AVISO (Homogeneidade): Para o fator '", fator, "', o p-valor do Levene é < 0.05. As variâncias NÃO são iguais."))
print("Para o TCC, reporte isso. O ANOVA é robusto a violações leves, mas é importante notar.")
}
}
# === FIM DA CORREÇÃO ===
# 4c. Teste Post-Hoc (Tukey HSD)
print("--- Resultados do Teste Post-Hoc (Tukey HSD) ---")
# Itera e mostra o Tukey HSD para todos os fatores
for (fator in fatores_independentes) {
print(paste("--- Comparação Post-Hoc (Tukey) para:", fator, "---"))
print(TukeyHSD(modelo, which = fator))
}
print(paste("--- ANÁLISE PARA:", metrica_nome, "CONCLUÍDA ---"))
}
# Itera sobre todas as métricas que foram realmente encontradas no arquivo
for (metrica in metricas_dependentes) {
executar_analise_anova(dados_limpos, metrica)
}
# Itera sobre todas as métricas que foram realmente encontradas no arquivo
for (metrica in metricas_dependentes) {
executar_analise_anova(dados_limpos, metrica)
}
# Verifica se as colunas existem
colunas_necessarias <- c(fatores_independentes, metricas_dependentes)
colunas_ausentes <- setdiff(colunas_necessarias, names(dados))
if (length(colunas_ausentes) > 0) {
print(paste("AVISO: As seguintes colunas não foram encontradas:", paste(colunas_ausentes, collapse=", ")))
# Remove da lista as métricas/fatores que não foram encontrados
metricas_dependentes <- setdiff(metricas_dependentes, colunas_ausentes)
fatores_independentes <- setdiff(fatores_independentes, colunas_ausentes)
}
colunas_para_analise <- c(fatores_independentes, metricas_dependentes)
# Limpeza e Preparação
dados_limpos <- dados %>%
mutate(across(all_of(fatores_independentes), as.factor)) %>%
mutate(top_k = as.factor(top_k),
temperature = as.factor(temperature)) %>%
select(all_of(colunas_para_analise)) %>%
na.omit()
print(paste("Dados carregados e limpos. Total de linhas para análise:", nrow(dados_limpos)))
executar_analise_anova <- function(dados, metrica_nome) {
print(paste("--- INICIANDO ANÁLISE PARA:", metrica_nome, "---"))
formula_anova <- as.formula(paste(
metrica_nome, "~", paste(fatores_independentes, collapse = " + ")
))
# 4a. Rodar o Modelo ANOVA
modelo <- aov(formula_anova, data = dados)
print("Resultados do ANOVA (Sumário do Modelo):")
print(summary(modelo))
# 4b. Verificar Pressupostos
residuos_modelo <- residuals(modelo)
# Teste de Normalidade (Shapiro-Wilk)
if (length(residuos_modelo) > 5000) {
print("Muitos resíduos (>5000) para Shapiro-Wilk. Usando uma amostra de 5000.")
shapiro_teste <- shapiro.test(sample(residuos_modelo, 5000))
} else {
shapiro_teste <- shapiro.test(residuos_modelo)
}
print("Teste de Normalidade (Shapiro-Wilk):")
print(shapiro_teste)
if (shapiro_teste$p.value < 0.05) {
print("AVISO (Normalidade): O p-valor do Shapiro-Wilk é < 0.05. Os resíduos NÃO são normais.")
print("Para o TCC, reporte isso e considere usar um teste não-paramétrico (ex: Kruskal-Wallis).")
}
# === CORREÇÃO DO TESTE DE LEVENE ===
print("Teste de Homogeneidade (Levene) - (Testando cada fator individualmente):")
# O Levene Test falha com fórmulas complexas (+).
# Vamos testar a homogeneidade para cada fator principal, um de cada vez.
for (fator in fatores_independentes) {
formula_levene <- as.formula(paste(metrica_nome, "~", fator))
print(paste("--- Resultado do Teste de Levene para o fator:", fator, "---"))
# Roda o teste para o fator atual
teste_levene <- leveneTest(formula_levene, data = dados)
print(teste_levene)
# Extrai o p-valor
levene_p_value <- teste_levene$`Pr(>F)`[1]
# H0 (Hipótese Nula): As variâncias são iguais.
# Se p < 0.05, as variâncias NÃO são iguais (violou o pressuposto).
if (levene_p_value < 0.05) {
print(paste("AVISO (Homogeneidade): Para o fator '", fator, "', o p-valor do Levene é < 0.05. As variâncias NÃO são iguais."))
print("Para o TCC, reporte isso. O ANOVA é robusto a violações leves, mas é importante notar.")
}
}
# === FIM DA CORREÇÃO ===
# 4c. Teste Post-Hoc (Tukey HSD)
print("--- Resultados do Teste Post-Hoc (Tukey HSD) ---")
# Itera e mostra o Tukey HSD para todos os fatores
for (fator in fatores_independentes) {
print(paste("--- Comparação Post-Hoc (Tukey) para:", fator, "---"))
print(TukeyHSD(modelo, which = fator))
}
print(paste("--- ANÁLISE PARA:", metrica_nome, "CONCLUÍDA ---"))
}
# Itera sobre todas as métricas que foram realmente encontradas no arquivo
for (metrica in metricas_dependentes) {
executar_analise_anova(dados_limpos, metrica)
}
source("C:/monografia/analise/main.R", echo=TRUE)
# Itera sobre todas as métricas que foram realmente encontradas no arquivo
for (metrica in metricas_dependentes) {
executar_analise_anova(dados_limpos, metrica)
}
source("C:/monografia/analise/main.R", echo=TRUE)
source("C:/monografia/analise/main.R", echo=TRUE)
# Itera sobre todas as métricas que foram realmente encontradas no arquivo
for (metrica in metricas_dependentes) {
executar_analise_anova(dados_limpos, metrica, fatores_para_analise)
}
source("C:/monografia/analise/main.R", echo=TRUE)
source("C:/monografia/analise/main.R", echo=TRUE)
# Exemplo de análise para 'faithfulness' (Anti-Alucinação)
executar_analise_anova(dados_limpos, paste0("faithfulness", LLM_JUIZ_SUFFIX))
# Exemplo de análise para 'faithfulness' (Anti-Alucinação)
executar_analise_anova(dados_limpos, paste0("faithfulness", LLM_JUIZ_SUFFIX))
# Esta função executa todo o pipeline de análise para uma métrica
executar_analise_anova <- function(dados, metrica_nome) {
print(paste("--- INICIANDO ANÁLISE PARA:", metrica_nome, "---"))
# Cria a fórmula do modelo.
# Vamos analisar os "Efeitos Principais" (o impacto de cada parâmetro isoladamente)
# Esta é a forma mais simples e robusta de começar.
formula_anova <- as.formula(paste(
metrica_nome, "~", paste(fatores_independentes, collapse = " + ")
))
# Modelo alternativo (mais avançado) com interações de 2 vias:
# formula_anova <- as.formula(paste(
#   metrica_nome, "~ (", paste(fatores_independentes, collapse = " + "), ")^2"
# ))
# 4a. Rodar o Modelo ANOVA
modelo <- aov(formula_anova, data = dados)
print("Resultados do ANOVA (Sumário do Modelo):")
print(summary(modelo))
# 4b. Verificar Pressupostos (Importante para o TCC)
# O ANOVA só é 100% válido se os resíduos forem normais e as variâncias homogêneas.
residuos_modelo <- residuals(modelo)
# 1. Teste de Normalidade dos Resíduos (Shapiro-Wilk)
# H0 (Hipótese Nula): Os dados são normalmente distribuídos.
# Se p < 0.05, os dados NÃO são normais.
if (length(residuos_modelo) > 5000) {
print("Muitos resíduos (>5000) para Shapiro-Wilk. Usando uma amostra.")
shapiro_teste <- shapiro.test(sample(residuos_modelo, 5000))
} else {
shapiro_teste <- shapiro.test(residuos_modelo)
}
print("Teste de Normalidade (Shapiro-Wilk):")
print(shapiro_teste)
# 2. Teste de Homogeneidade das Variâncias (Levene)
# H0 (Hipótese Nula): As variâncias entre os grupos são iguais.
# Se p < 0.05, as variâncias NÃO são iguais (heterocedasticidade).
print("Teste de Homogeneidade (Levene):")
#print(leveneTest(formula_anova, data = dados))
# Mensagem de Aviso para o TCC
if (shapiro_teste$p.value < 0.05) {
print("AVISO (Normalidade): O p-valor do Shapiro-Wilk é < 0.05. Os resíduos NÃO são normais.")
print("Considere usar um teste não-paramétrico (ex: Kruskal-Wallis) ou um GLM (Modelo Linear Generalizado) para sua análise final.")
}
# 4c. Teste Post-Hoc (Tukey HSD)
# Se o ANOVA mostrou que um fator é significativo (ex: Pr(>F) < 0.05),
# este teste nos diz QUAIS grupos são diferentes entre si.
print("--- Resultados do Teste Post-Hoc (Tukey HSD) ---")
# Vamos fazer como exemplo para os 3 fatores mais importantes de RAG:
print("Comparação para 'search_type':")
print(TukeyHSD(modelo, which = "search_type"))
print("Comparação para 'chunking_strategy':")
print(TukeyHSD(modelo, which = "chunking_strategy"))
print("Comparação para 'system_prompt_override':")
print(TukeyHSD(modelo, which = "system_prompt_override"))
print(paste("--- ANÁLISE PARA:", metrica_nome, "CONCLUÍDA ---"))
}
# Exemplo de análise para 'faithfulness' (Anti-Alucinação)
executar_analise_anova(dados_limpos, paste0("faithfulness", LLM_JUIZ_SUFFIX))
# Exemplo de análise para 'answer_correctness' (Correção Semântica)
executar_analise_anova(dados_limpos, paste0("answer_correctness", LLM_JUIZ_SUFFIX))
source("C:/monografia/analise/main.R", echo=TRUE)
source("C:/monografia/analise/main.R", echo=TRUE)
source("C:/monografia/analise/main.R", echo=TRUE)
source("C:/monografia/analise/main.R", echo=TRUE)
source("C:/monografia/analise/main.R", echo=TRUE)
# Itera sobre todas as métricas que foram realmente encontradas no arquivo
for (metrica in metricas_dependentes) {
# Passa o nome do arquivo de saída para a função
executar_analise_anova(dados_limpos, metrica, fatores_para_analise, ARQUIVO_SAIDA_ANALISE)
}
print("\n\n--- ANÁLISE COMPLETA ---")
print(paste("Todos os resultados estatísticos foram salvos em:", ARQUIVO_SAIDA_ANALISE))
source("C:/monografia/analise/main.R", echo=TRUE)
source("C:/monografia/analise/main.R", echo=TRUE)
source("C:/monografia/analise/main.R", echo=TRUE)
View(dados_limpos)
